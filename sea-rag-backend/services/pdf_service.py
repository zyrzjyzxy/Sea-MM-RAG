from __future__ import annotations
import os
import shutil
import io
import math
import json
import argparse
import glob
from pathlib import Path
from typing import Dict, Any, List, Optional
import fitz  # PyMuPDF
from PIL import Image
from langchain_unstructured import UnstructuredLoader
from unstructured.partition.pdf import partition_pdf
from html2text import html2text
from dotenv import load_dotenv
import matplotlib
matplotlib.use('Agg')
import matplotlib.patches as patches
from matplotlib.figure import Figure
from matplotlib.backends.backend_agg import FigureCanvasAgg
import numpy as np
import base64
import requests
import time

# åŠ è½½ç¯å¢ƒå˜é‡ (å¦‚æœéœ€è¦)
load_dotenv(override=True)

# ---------------------------------------------------------------------------
# 1. ç¯å¢ƒé…ç½® (Poppler è·¯å¾„ç­‰)
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# 1. ç¯å¢ƒé…ç½® (Poppler è·¯å¾„ç­‰)
# ---------------------------------------------------------------------------

# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå…¶æ¬¡ä½¿ç”¨ç¡¬ç¼–ç è·¯å¾„
POPPLER_PATH = os.getenv("POPPLER_PATH", r"V:\RAG\tools\poppler-25.12.0\Library\bin")
TESSERACT_PATH = os.getenv("TESSERACT_PATH", r"C:\Program Files\Tesseract-OCR\tesseract.exe")

def setup_environment():
    """é…ç½®è¿è¡Œæ‰€éœ€çš„ç¯å¢ƒå˜é‡"""
    # 1. Poppler
    if os.path.exists(POPPLER_PATH):
        if POPPLER_PATH not in os.environ["PATH"]:
            os.environ["PATH"] += os.pathsep + POPPLER_PATH
            print(f"âœ… Poppler è·¯å¾„å·²ä¸´æ—¶æ·»åŠ : {POPPLER_PATH}")
    else:
        # ä»…å½“é»˜è®¤è·¯å¾„ä¹Ÿä¸å­˜åœ¨æ—¶æ‰è­¦å‘Šï¼Œé¿å…è¯¯æŠ¥
        if not shutil.which("pdftoppm"): # ç®€å•æ£€æŸ¥
             print(f"âŒ è­¦å‘Šï¼šæœªæ‰¾åˆ° Poppler è·¯å¾„ï¼Œä¸”æœªåœ¨ PATH ä¸­å‘ç°ç›¸å…³å·¥å…·ã€‚PDFè§£æå¯èƒ½å¤±è´¥ã€‚")
             print(f"    å½“å‰é…ç½®è·¯å¾„: {POPPLER_PATH}")

    # 2. Tesseract
    # æ£€æŸ¥æ˜¯å¦å·²åœ¨ PATH ä¸­
    if not shutil.which("tesseract"):
        # å¦‚æœ TESSERACT_PATH æŒ‡å‘æ–‡ä»¶ï¼Œå–å…¶ç›®å½•
        tess_dir = TESSERACT_PATH
        if os.path.isfile(TESSERACT_PATH):
            tess_dir = os.path.dirname(TESSERACT_PATH)
        
        if os.path.exists(tess_dir):
            if tess_dir not in os.environ["PATH"]:
                os.environ["PATH"] += os.pathsep + tess_dir
                print(f"âœ… Tesseract è·¯å¾„å·²ä¸´æ—¶æ·»åŠ : {tess_dir}")
        else:
             print(f"âŒ è­¦å‘Šï¼šæœªæ‰¾åˆ° Tesseractï¼Œä¸”æœªåœ¨ PATH ä¸­å‘ç°ã€‚OCR å¯èƒ½æ— æ³•ä½¿ç”¨ã€‚")
             print(f"    å½“å‰å°è¯•è·¯å¾„: {TESSERACT_PATH}")
             print(f"    è¯·å®‰è£… Tesseract-OCR å¹¶æ·»åŠ åˆ° PATHï¼Œæˆ–åœ¨ .env ä¸­è®¾ç½® TESSERACT_PATH")

setup_environment()

# ---------------------------------------------------------------------------
# 2. ç›®å½•ç®¡ç†
# ---------------------------------------------------------------------------

# å°† Path è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼Œé¿å…è¿è¡Œç›®å½•ä¸åŒå¯¼è‡´æ‰¾ä¸åˆ°æ–‡ä»¶
# ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡é…ç½®
DATA_ROOT = Path(os.getenv("DATA_ROOT", "data")).resolve()

def set_data_root(path: str):
    global DATA_ROOT
    DATA_ROOT = Path(path).resolve() # å¼ºåˆ¶è½¬ä¸ºç»å¯¹è·¯å¾„

def get_workdir(file_id: str) -> Path:
    d = DATA_ROOT / file_id
    d.mkdir(parents=True, exist_ok=True)
    return d

def get_original_pdf_path(file_id: str) -> Path:
    return get_workdir(file_id) / "original.pdf"

def find_pdf_file(file_id: str) -> Path:
    """æŸ¥æ‰¾ç›®å½•ä¸‹çš„ PDF æ–‡ä»¶ã€‚ä¼˜å…ˆæ‰¾ original.pdfï¼Œå¦‚æœæ²¡æœ‰ï¼Œæ‰¾ç¬¬ä¸€ä¸ª .pdf æ–‡ä»¶"""
    workdir = get_workdir(file_id)
    
    # 1. ä¼˜å…ˆæ£€æŸ¥æ ‡å‡†å‘½å
    original_path = workdir / "original.pdf"
    if original_path.exists():
        return original_path
        
    # 2. å¦åˆ™æŸ¥æ‰¾ä»»æ„ PDF
    pdf_files = list(workdir.glob("*.pdf"))
    if pdf_files:
        return pdf_files[0] # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ PDF
        
    # 3. é»˜è®¤è¿”å›æ ‡å‡†è·¯å¾„ï¼ˆè™½ç„¶ä¸å­˜åœ¨ï¼Œä½†ç”¨äºæŠ¥é”™æç¤ºï¼‰
    return original_path

def get_markdown_output_path(file_id: str) -> Path:
    return get_workdir(file_id) / "output.md"

def get_segments_path(file_id: str) -> Path:
    return get_workdir(file_id) / "segments.json"

def get_images_dir(file_id: str) -> Path:
    p = get_workdir(file_id) / "images"
    p.mkdir(parents=True, exist_ok=True)
    return p

# ---------------------------------------------------------------------------
# 3. VLM å›¾åƒç†è§£åŠŸèƒ½
# ---------------------------------------------------------------------------

MODEL_NAME = os.getenv("VLM_MODEL_NAME", "deepseek-ai/deepseek-vl2")

def encode_image_to_base64(image_path: str) -> Optional[str]:
    """å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸º Base64 ç¼–ç """
    if not os.path.exists(image_path):
        print(f"âŒ [DEBUG] encode_image_to_base64: æ‰¾ä¸åˆ°æ–‡ä»¶ {image_path} (PWD: {os.getcwd()})")
        return None
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def get_vlm_caption(image_path: str) -> str:
    """è°ƒç”¨ API è§£æå›¾ç‰‡ï¼Œè·å– Caption"""
    # ä¼˜å…ˆè¯»å– SILICONFLOW_API_KEYï¼Œå…¶æ¬¡ SILICON_API_KEY (å…¼å®¹ .env)
    api_key = os.getenv("SILICONFLOW_API_KEY") or os.getenv("SILICON_API_KEY")
    
    if not api_key:
        print("âš ï¸ [DEBUG] æœªé…ç½® API Keyï¼Œè·³è¿‡")
        return "> **AIè§†è§‰è§£æ**ï¼š(æœªé…ç½® API Keyï¼Œæ— æ³•è§£æ)"

    b64_img = encode_image_to_base64(image_path)
    if not b64_img: 
        print(f"âš ï¸ [DEBUG] å›¾ç‰‡è½¬ Base64 å¤±è´¥: {image_path}")
        return ""

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    # é’ˆå¯¹è¿ç»´åœºæ™¯ä¼˜åŒ–çš„ Prompt (å‚è€ƒ notebook)
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªç²¾é€šæµ·æ´‹å·¥ç¨‹ä¸æ— äººè‰‡è®¾å¤‡çš„è¿ç»´ä¸“å®¶ã€‚è¯·ç®€æ˜æ‰¼è¦åœ°è§£æå›¾ç‰‡ã€‚"
    user_prompt = "åˆ†æè¿™å¼ å›¾ç‰‡ã€‚å¦‚æœæ˜¯è®¾å¤‡éƒ¨ä»¶ï¼Œè¯·è¯†åˆ«åç§°å’ŒçŠ¶æ€ï¼ˆå¦‚è…èš€ã€æ–­è£‚ï¼‰ï¼›å¦‚æœæ˜¯å›¾è¡¨ï¼Œè¯·æå–å…³é”®æ•°å€¼ï¼›å¦‚æœæ˜¯ç”µè·¯å›¾ï¼Œè¯·è¯´æ˜è¿æ¥å…³ç³»ã€‚è¯·ç›´æ¥è¾“å‡ºç»“è®ºã€‚"

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": [
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}},
                {"type": "text", "text": user_prompt}
            ]}
        ],
        "temperature": 0.1,
        "max_tokens": 512
    }

    # API URL
    api_url = os.getenv("VLM_API_URL", "https://api.siliconflow.cn/v1/chat/completions")
    
    max_retries = 3
    retry_delay = 2 # seconds

    for attempt in range(max_retries + 1):
        try:
            start_time = time.time()
            # æ‰“å°æ—¥å¿— (ä»…é¦–æ¬¡)
            if attempt == 0:
                print(f"    [VLM] æ­£åœ¨åˆ†æå›¾ç‰‡: {os.path.basename(image_path)} ...")
            else:
                print(f"    âš ï¸ [VLM] é‡è¯• ({attempt}/{max_retries}): {os.path.basename(image_path)} ...")

            response = requests.post(api_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            content = result['choices'][0]['message']['content'].strip()
            
            duration = time.time() - start_time
            print(f"    âœ… VLM åˆ†æå®Œæˆ (è€—æ—¶ {duration:.2f}s, å°è¯• {attempt+1}æ¬¡): {content[:30]}...")
            return content
            
        except (requests.exceptions.RequestException, requests.exceptions.HTTPError, ConnectionError) as e:
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…å¹¶é‡è¯•
            if attempt < max_retries:
                wait_time = retry_delay * (2 ** attempt)
                print(f"    âš ï¸ VLM è°ƒç”¨å¤±è´¥: {e}. ç­‰å¾… {wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                print(f"    âŒ VLM æœ€ç»ˆå¤±è´¥: {e}")
                return f"(VLM å¤„ç†å‘ç”Ÿé”™è¯¯ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {str(e)})"
                
        except Exception as e:
            # éç½‘ç»œ/HTTPé”™è¯¯ï¼Œä¸é‡è¯•ï¼Œç›´æ¥è¿”å›
            print(f"    âŒ VLM éæœŸå¾…é”™è¯¯: {e}")
            return f"(VLM å¤„ç†å‘ç”Ÿé”™è¯¯: {str(e)})"

# ---------------------------------------------------------------------------
# 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ---------------------------------------------------------------------------

def save_upload_file(file_id: str, upload_bytes: bytes, filename: str) -> Dict[str, Any]:
    """ä¿å­˜ä¸Šä¼ çš„ PDF æ–‡ä»¶"""
    # è¿™é‡Œæˆ‘ä»¬è¿˜æ˜¯å€¾å‘äºä¿å­˜ä¸º original.pdf ä»¥ä¿æŒæ ‡å‡†åŒ–ï¼Œ
    # ä½†ä¹Ÿå¯ä»¥ä¿®æ”¹ä¸ºä¿å­˜åŸæ–‡ä»¶åï¼Œåªè¦åç»­ find_pdf_file èƒ½æ‰¾åˆ°å³å¯ã€‚
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿™é‡Œæš‚æ—¶ä¿æŒä¿å­˜ä¸º original.pdfï¼Œ
    # ä½†ä½ ä¹Ÿå®Œå…¨å¯ä»¥æ”¹ä¸º: save_path = get_workdir(file_id) / filename
    
    work_dir = get_workdir(file_id)
    pdf_path = work_dir / "original.pdf"
    pdf_path.write_bytes(upload_bytes)
    
    with fitz.open(pdf_path) as doc:
        pages = doc.page_count
        
    # ä¿å­˜å…ƒæ•°æ® (æ–°å¢)
    meta_path = work_dir / "meta.json"
    meta_data = {
        "id": file_id,
        "original_filename": filename,
        "upload_time": time.time(),
        "size_bytes": len(upload_bytes),
        "page_count": pages
    }
    try:
        meta_path.write_text(json.dumps(meta_data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e:
        print(f"âš ï¸ Warning: Failed to save meta.json: {e}")
        
    return {
        "file_id": file_id,
        "filename": filename,
        "page_count": pages,
        "local_path": str(pdf_path)
    }

def delete_file(file_id: str) -> bool:
    """åˆ é™¤æŒ‡å®šæ–‡ä»¶ ID çš„æ‰€æœ‰æ•°æ®"""
    work_dir = get_workdir(file_id)
    if work_dir.exists():
        try:
            shutil.rmtree(work_dir)
            print(f"âœ… å·²åˆ é™¤æ–‡ä»¶ç›®å½•: {work_dir}")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡ä»¶ç›®å½•å¤±è´¥: {e}")
            return False
    return False

def convert_pdf_to_markdown(file_id: str, strategy: str = "hi_res") -> Dict[str, Any]:
    """å®Œæ•´æµç¨‹ï¼šæå– PDF å†…å®¹å¹¶è½¬æ¢ä¸º Markdown"""
    
    # è‡ªåŠ¨æŸ¥æ‰¾ PDF æ–‡ä»¶
    pdf_path_obj = find_pdf_file(file_id)
    pdf_path = str(pdf_path_obj)
    
    out_md_path = get_markdown_output_path(file_id)
    img_dir = get_images_dir(file_id)
    
    print(f"[*] æ­£åœ¨å¼€å§‹å¤„ç†: {file_id}")
    print(f"    PDFè·¯å¾„: {pdf_path}")
    print(f"    ç­–ç•¥: {strategy}")
    
    if not pdf_path_obj.exists():
        raise FileNotFoundError(f"åœ¨ç›®å½• {pdf_path_obj.parent} ä¸‹æœªæ‰¾åˆ°ä»»ä½• PDF æ–‡ä»¶")

    # 1. è§£æå…ƒç´ 
    partition_kwargs = {
        "filename": pdf_path,
        "strategy": strategy,
        "infer_table_structure": (strategy == "hi_res"),
    }
    
    # æ ¹æ®éœ€è¦å¯ç”¨ OCR
    if strategy == "hi_res":
        # partition_kwargs["ocr_languages"] = ["chi_sim", "eng"]
        pass

    elements = partition_pdf(**partition_kwargs)

    # ä¿å­˜è§£æç»“æœï¼ˆSegmentsï¼‰åˆ° JSONï¼Œç”¨äºåç»­å¯è§†åŒ–
    try:
        segments = []
        for el in elements:
            if hasattr(el, "to_dict"):
                segments.append(el.to_dict())
            else:
                # Fallback if to_dict not available
                segments.append({
                    "category": getattr(el, "category", "Uncategorized"),
                    "text": str(el),
                    "metadata": getattr(el, "metadata", {}).__dict__ if hasattr(getattr(el, "metadata", None), "__dict__") else {}
                })
        
        segments_path = get_segments_path(file_id)
        segments_path.write_text(json.dumps(segments, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"[*] è§£æ Segments å·²ä¿å­˜: {segments_path}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ Segments å¤±è´¥: {e}")

    # 2. æå–å›¾ç‰‡å¹¶è°ƒç”¨ VLM
    image_map = {}
    image_caption_map = {} # å­˜å‚¨å›¾ç‰‡æè¿°
    with fitz.open(pdf_path) as doc:
        for page_num, page in enumerate(doc, start=1):
            image_map[page_num] = []
            for img_index, img in enumerate(page.get_images(full=True), start=1):
                xref = img[0]
                pix = fitz.Pixmap(doc, xref)
                img_name = f"page{page_num}_img{img_index}.png"
                img_path = img_dir / img_name
                
                if pix.n < 5:
                    pix.save(str(img_path))
                else:
                    pix = fitz.Pixmap(fitz.csRGB, pix)
                    pix.save(str(img_path))
                
                image_map[page_num].append(img_name)
                
                # ------ VLM è°ƒç”¨ ------
                # æå–åç«‹å³è°ƒç”¨ VLM è·å–æè¿°
                caption = get_vlm_caption(str(img_path))
                if caption:
                    image_caption_map[img_name] = caption
                # ---------------------
    
    print(f"[*] å›¾ç‰‡æå–å®Œæˆï¼Œä¿å­˜åœ¨: {img_dir}")

    # 3. ç»„è£… Markdown
    md_lines: List[str] = []
    inserted_images = set()
    
    def insert_page_images(p_num):
        """Helper: æ’å…¥æŒ‡å®šé¡µé¢çš„æ‰€æœ‰æœªæ’å…¥å›¾ç‰‡"""
        if p_num in image_map:
            for name in image_map[p_num]:
                if (p_num, name) not in inserted_images:
                    md_lines.append(f"\n![Image](./images/{name})\n")
                    if name in image_caption_map:
                        caption_text = image_caption_map[name]
                        md_lines.append(f"> **AIè§†è§‰è§£æ**ï¼š{caption_text}\n")
                    inserted_images.add((p_num, name))

    # --- Helper to insert page break marker ---
    def insert_page_break(p_num):
        md_lines.append(f"\n<!-- PAGE_BREAK: {p_num} -->\n")

    last_page_seen = 0
    
    for el in elements:
        category = getattr(el, "category", None)
        text = (getattr(el, "text", "") or "").strip()
        metadata = getattr(el, "metadata", None)
        page_num = getattr(metadata, "page_number", None) if metadata else None

        # --- Check for page transition to flush images of previous pages ---
        if page_num and page_num > last_page_seen:
            start_p = last_page_seen + 1 if last_page_seen > 0 else 1
            
            # è¡¥é½ä¸Šä¸€é¡µ(åŠä¸­é—´è·³è¿‡çš„é¡µ)çš„å›¾ç‰‡ï¼Œå¹¶æ’å…¥å¯¹åº”çš„åˆ†é¡µæ ‡è®°
            for p in range(start_p, page_num):
                insert_page_break(p)
                insert_page_images(p)
            
            # æ’å…¥å½“å‰é¡µçš„åˆ†é¡µæ ‡è®°
            insert_page_break(page_num)
            last_page_seen = page_num

        if not text and category != "Image":
            continue

        if category == "Title":
            md_lines.append(f"# {text}\n")
        elif category in ["Header", "Subheader"]:
            md_lines.append(f"## {text}\n")
        elif category == "Table":
            html = getattr(metadata, "text_as_html", None) if metadata else None
            if html:
                md_lines.append(html2text(html) + "\n")
            else:
                md_lines.append(text + "\n")
        elif category == "Image" and page_num:
            # å¦‚æœ unstructured è¯†åˆ«åˆ°äº†å›¾ç‰‡å ä½ç¬¦ï¼Œç›´æ¥åœ¨æ­¤å¤„æ’å…¥
            insert_page_images(page_num)
        else:
            md_lines.append(text + "\n")

    # --- Final Flush: å¤„ç†æœ€åä¸€é¡µæˆ–å‰©ä½™é¡µé¢çš„å›¾ç‰‡ ---
    max_p = max(image_map.keys()) if image_map else 0
    start_p = last_page_seen if last_page_seen > 0 else 1
    for p in range(start_p, max_p + 1):
        insert_page_images(p)

    # å†™å…¥æ–‡ä»¶
    print(f"[*] æ­£åœ¨å†™å…¥ Markdown æ–‡ä»¶: {out_md_path}")
    markdown_content = "\n".join(md_lines)
    out_md_path.write_text(markdown_content, encoding="utf-8")
    
    return {
        "markdown_path": str(out_md_path),
        "images_dir": str(img_dir),
        "content_preview": markdown_content[:500] if markdown_content else ""
    }

def render_parsed_page(file_id: str, page_number: int) -> Optional[bytes]:
    """
    æ¸²æŸ“æŒ‡å®šé¡µé¢çš„è§£æç»“æœï¼ˆå¸¦è¾¹æ¡†ï¼‰ï¼Œè¿”å› PNG å›¾ç‰‡å­—èŠ‚æµ
    """
    try:
        # 1. åŠ è½½ Segments
        seg_path = get_segments_path(file_id)
        if not seg_path.exists():
            return None
            
        segments = json.loads(seg_path.read_text(encoding="utf-8"))
        
        # ç­›é€‰å½“å‰é¡µçš„ segments (æ³¨æ„ unstructured çš„ page_number å¯èƒ½æ˜¯1-based)
        page_segments = [
            s for s in segments 
            if s.get("metadata", {}).get("page_number") == page_number
        ]
        
        if not page_segments:
            # è¯¥é¡µæ²¡æœ‰è¯†åˆ«å‡ºå…ƒç´ ï¼Œæˆ–è€…é¡µç ä¸å¯¹ï¼Ÿ
            # å°è¯• fallbackï¼šå¦‚æœ segments é‡Œæ²¡æœ‰ page_numberï¼Œå¯èƒ½æ˜¯ä¸æ”¯æŒåˆ†é¡µï¼Ÿ
            # ä½† PDF partition é€šå¸¸æœ‰ã€‚å¦‚æœä¸ºç©ºï¼Œå¯èƒ½çœŸçš„æ˜¯ç©ºç™½é¡µã€‚
            pass

        # 2. åŠ è½½åŸå§‹ PDF é¡µé¢ä½œä¸ºèƒŒæ™¯
        pdf_path = find_pdf_file(file_id)
        doc = fitz.open(pdf_path)
        if page_number < 1 or page_number > len(doc):
            return None
            
        page = doc[page_number - 1]
        pix = page.get_pixmap()
        pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        # 3. ç»˜å›¾ (Matplotlib)
        # ä¿æŒå›¾åƒåŸå§‹æ¯”ä¾‹ï¼Œ1px = 1 unit?
        # Matplotlibé»˜è®¤DPI=100. figsize=(w_inch, h_inch).
        # ä¸ºäº†ç²¾ç¡®å¯¹é½ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨åƒç´ å°ºå¯¸ã€‚
        
        width_px, height_px = pix.width, pix.height
        dpi = 100
        fig = Figure(figsize=(width_px / dpi, height_px / dpi), dpi=dpi)
        # å»é™¤è¾¹è·
        ax = fig.add_axes([0, 0, 1, 1])
        ax.axis("off")
        
        ax.imshow(pil_image)
        
        category_to_color = {
            "Title": "orchid",
            "Image": "forestgreen", 
            "Table": "tomato",
            "Header": "orange",
            "Footer": "gray"
        }
        
        for segment in page_segments:
            # æ£€æŸ¥æ˜¯å¦æœ‰åæ ‡
            if "coordinates" not in segment.get("metadata", {}):
                continue
                
            coords = segment["metadata"]["coordinates"]
            points = coords.get("points") # list of [x, y]
            layout_w = coords.get("layout_width")
            layout_h = coords.get("layout_height")
            
            if not points or not layout_w or not layout_h:
                continue
                
            # åæ ‡è½¬æ¢ï¼šLayout -> Image Pixel
            # unstructured points are usually top-left, bottom-left... polygon?
            # points is list of (x, y).
            
            scaled_points = [
                (x * width_px / layout_w, y * height_px / layout_h)
                for x, y in points
            ]
            
            category = segment.get("category", "Uncategorized")
            box_color = category_to_color.get(category, "deepskyblue")
            
            poly = patches.Polygon(
                scaled_points, 
                linewidth=2, 
                edgecolor=box_color, 
                facecolor="none"
            )
            ax.add_patch(poly)
            
            # å¯é€‰ï¼šç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            # x0, y0 = scaled_points[0]
            # ax.text(x0, y0, category, color=box_color, fontsize=8, backgroundcolor="white")

        # æ¸²æŸ“åˆ° Buffer
        canvas = FigureCanvasAgg(fig)
        buf = io.BytesIO()
        canvas.print_png(buf)
        img_data = buf.getvalue()
        buf.close()
        doc.close()
        
        return img_data
        
    except Exception as e:
        print(f"âŒ render_parsed_page é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

# ---------------------------------------------------------------------------
# 4. å‘½ä»¤è¡Œå…¥å£
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    # --- æµ‹è¯•ä»£ç  & è¿è¡ŒæŒ‡å— ---
    # ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹ CMD å‘½ä»¤è¿è¡Œæ­¤æµ‹è¯•ï¼š
    # 
    # 1. é»˜è®¤å¿«é€Ÿæµ‹è¯• (Fast ç­–ç•¥):
    #    python v:\RAG\sea-rag-backend\services\pdf_service.py
    # 
    # 2. é«˜ç²¾åº¦æµ‹è¯• (Hi_res ç­–ç•¥ï¼ŒåŒ…å«è¡¨æ ¼è¯†åˆ«):
    #    python v:\RAG\sea-rag-backend\services\pdf_service.py --strategy hi_res
    # 
    # 3. æŒ‡å®šè‡ªå®šä¹‰æ–‡ä»¶ ID å’Œæ•°æ® root:
    #    python v:\RAG\sea-rag-backend\services\pdf_service.py --file_id my_pdf_01 --data_root ./my_data
    # 
    # æ³¨æ„ï¼šç¡®ä¿å·²å®‰è£…ä¾èµ–ï¼špip install requests pymupdf pillow langchain-unstructured unstructured html2text python-dotenv
    
    parser = argparse.ArgumentParser(description="PDF è½¬ Markdown + VLM å›¾åƒç†è§£ æµ‹è¯•å·¥å…·")
    parser.add_argument("--strategy", type=str, default="fast", choices=["fast", "hi_res"], help="è§£æç­–ç•¥: fast(å¿«é€Ÿ) æˆ– hi_res(é«˜ç²¾åº¦/å¸¦OCR)")
    parser.add_argument("--file_id", type=str, default="test_001", help="æµ‹è¯•æ–‡ä»¶å¤¹åç§°")
    parser.add_argument("--data_root", type=str, default="data", help="æ•°æ®æ ¹ç›®å½•")
    args = parser.parse_args()

    # 1. é…ç½®å…¨å±€å˜é‡
    set_data_root(args.data_root)
    file_id = args.file_id
    strategy = args.strategy

    print(f"\n{'='*50}")
    print(f">>> å¯åŠ¨ PDF + VLM æœåŠ¡æµ‹è¯•")
    print(f"    æ•°æ®æ ¹ç›®å½•: {DATA_ROOT}")
    print(f"    æ–‡ä»¶ ID:    {file_id}")
    print(f"    è§£æç­–ç•¥:   {strategy}")
    print(f"    VLM æ¨¡å‹:   {MODEL_NAME}")
    print(f"{'='*50}\n")

    # 2. å‡†å¤‡æµ‹è¯• PDF æ–‡ä»¶
    pdf_path_obj = find_pdf_file(file_id)
    if not pdf_path_obj.exists():
        print(f"[!] ç›®å½• {get_workdir(file_id)} ä¸‹æœªæ‰¾åˆ° PDF æ–‡ä»¶")
        print("    æ­£åœ¨è‡ªåŠ¨åˆ›å»ºåŒ…å«æ–‡å­—å’Œæµ‹è¯•è¯´æ˜çš„ PDF æ–‡ä»¶...")
        try:
            get_workdir(file_id).mkdir(parents=True, exist_ok=True)
            doc = fitz.open()
            page = doc.new_page()
            # æ’å…¥ä¸€äº›æµ‹è¯•æ–‡æœ¬
            page.insert_text((50, 72), "VLM Integration Test Document", fontsize=20, color=(0, 0, 1))
            page.insert_text((50, 120), f"Current Strategy: {strategy}", fontsize=12)
            page.insert_text((50, 140), "If there are images in the PDF, they will be processed by VLM.", fontsize=12)
            
            # æç¤ºç”¨æˆ·æ‰‹åŠ¨æ”¾å…¥å¸¦å›¾ç‰‡çš„ PDF æ•ˆæœæ›´å¥½
            print("    ğŸ’¡ æç¤ºï¼šè‹¥éœ€æµ‹è¯•å›¾ç‰‡ç†è§£ï¼Œè¯·æ‰‹åŠ¨å°†å«å›¾ç‰‡çš„ PDF æ”¾å…¥ä¸Šè¿°ç›®å½•å¹¶é‡å‘½åä¸º original.pdf")
            
            save_path = get_workdir(file_id) / "original.pdf"
            doc.save(str(save_path))
            doc.close()
            print(f"    âœ… æµ‹è¯• PDF å·²ç”Ÿæˆ: {save_path}")
        except Exception as e:
            print(f"âŒ æ— æ³•åˆ›å»ºæµ‹è¯• PDF: {e}")
            exit(1)
    
    # 3. æ‰§è¡Œè½¬æ¢æµç¨‹
    try:
        print("[*] æ­£åœ¨æ‰§è¡Œ convert_pdf_to_markdown (åŒ…å« VLM è°ƒç”¨)...")
        res = convert_pdf_to_markdown(file_id, strategy=strategy)
        
        print(f"\n{'-'*50}")
        print(f"âœ… è½¬æ¢æµç¨‹å·²å®Œæˆï¼")
        print(f"ğŸ“„ Markdown è·¯å¾„: {res['markdown_path']}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡ç›®å½•:     {res['images_dir']}")
        print(f"{'-'*50}")
        
        # æ£€æŸ¥è¾“å‡ºå†…å®¹ä¸­æ˜¯å¦åŒ…å« AI æè¿°
        content = res['content_preview']
        if "AI è§†è§‰åˆ†æ" in content:
            print("ğŸ‰ æµ‹è¯•æˆåŠŸï¼šåœ¨ç”Ÿæˆçš„ Markdown ä¸­å‘ç°äº† VLM æè¿°å†…å®¹ï¼")
        
        print(f"\né¢„è§ˆå†…å®¹ (å‰ 500 å­—):\n{'.' * 30}\n{content}\n{'.' * 30}")
        
    except Exception as e:
        import traceback
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:")
        traceback.print_exc()
        exit(1)